{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYrJZXKDVfrTEOLm7WVKOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleesia/opencv/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SV12jcd1kxe",
        "colab_type": "code",
        "outputId": "cd6b6752-2082-4fb6-e733-dc890cf7bffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 24, 3)\n",
        "        self.bnm1 = nn.BatchNorm2d(24)\n",
        "        self.conv2 = nn.Conv2d(24, 120, 3, padding=1)\n",
        "        self.bnm2 = nn.BatchNorm2d(120)\n",
        "        self.conv3 = nn.Conv2d(120, 360, 4)\n",
        "        self.bnm3 = nn.BatchNorm2d(360)\n",
        "        self.conv4 = nn.Conv2d(360, 1080, 3, padding=1)\n",
        "        self.bnm4 = nn.BatchNorm2d(1080)\n",
        "        self.fc1 = nn.Linear(9*1080, 3600)\n",
        "        self.fc2 = nn.Linear(3600, 648)\n",
        "        self.fc3 = nn.Linear(648, 108)\n",
        "        self.fc4 = nn.Linear(108, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm4(x)\n",
        "        x = x.view(-1, 9*1080)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "lr=0.15\n",
        "momentum = 0.5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch,log_interval):\n",
        "    model.train()\n",
        "    avg_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # zero the gradient buffers\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() # Does the update\n",
        "        avg_loss+=F.nll_loss(output, target, reduction='sum').item()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{:5.0f}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "    avg_loss/=len(train_loader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss,accuracy\n",
        "\n",
        "epochs = 3\n",
        "log_interval = 400\n",
        "save_model = False\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "accuracy_list = []\n",
        "#optimizer = optim.Adam(model.parameters(), 0.00001)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer = optim.Adam(model.parameters(), 0.00001/epoch)\n",
        "\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "if (save_model):\n",
        "    torch.save(model.state_dict(),\"CIFAR_cnn.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bnm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(24, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(120, 360, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (bnm3): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(360, 1080, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm4): BatchNorm2d(1080, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=9720, out_features=3600, bias=True)\n",
            "  (fc2): Linear(in_features=3600, out_features=648, bias=True)\n",
            "  (fc3): Linear(in_features=648, out_features=108, bias=True)\n",
            "  (fc4): Linear(in_features=108, out_features=10, bias=True)\n",
            ")\n",
            "Train Epoch: 1 [    0/50000 (0%)]\tLoss: 2.318363\n",
            "Train Epoch: 1 [ 6400/50000 (13%)]\tLoss: 1.695282\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.289229\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.249509\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.017151\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.415570\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.052644\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.891578\n",
            "\n",
            "Test set: Average loss: 1.0225, Accuracy: 6359/10000 (63.6%)\n",
            "\n",
            "Train Epoch: 2 [    0/50000 (0%)]\tLoss: 0.939138\n",
            "Train Epoch: 2 [ 6400/50000 (13%)]\tLoss: 0.852500\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.062883\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.503792\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.772439\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.829594\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.787671\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.616190\n",
            "\n",
            "Test set: Average loss: 0.9002, Accuracy: 6856/10000 (68.6%)\n",
            "\n",
            "Train Epoch: 3 [    0/50000 (0%)]\tLoss: 0.724675\n",
            "Train Epoch: 3 [ 6400/50000 (13%)]\tLoss: 0.601266\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.915067\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.968467\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.585592\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.566513\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.612207\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.697830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3djzkFWFSjJ",
        "colab_type": "code",
        "outputId": "5007d7d3-2a2c-4849-efc5-423f9c1fb828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(1000):\n",
        "            label = labels[i]\n",
        "            y_true.append(classes[labels[i]])\n",
        "            y_pred.append(classes[predicted[i]])\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "import sklearn.metrics as metr\n",
        "mtrx = metr.confusion_matrix(y_true, y_pred, labels=classes)\n",
        "print(\"Confusion matrix: \\n\", mtrx)\n",
        "\n",
        "precisions = [0,0,0,0,0,0,0,0,0,0]\n",
        "recalls = [0,0,0,0,0,0,0,0,0,0]\n",
        "f1_scores = [0,0,0,0,0,0,0,0,0,0]\n",
        "for i in range(10):\n",
        "    suma_row=0\n",
        "    suma_column=0\n",
        "    for j in range(10):\n",
        "        suma_row += mtrx[i][j]\n",
        "        suma_column += mtrx[j][i]\n",
        "    precisions[i] = mtrx[i][i]/(suma_row)*100\n",
        "    recalls[i] = mtrx[i][i]/(suma_column)*100\n",
        "    f1_scores[i] = 2 * (precisions[i] * recalls[i])/(precisions[i] + recalls[i])\n",
        "    print('Accuracy of %5s : %2d %%  Precision: %4s %%  Recall: %4d %%  F1-score: %4s %%' % (classes[i], 100 * class_correct[i] / class_total[i], precisions[i], recalls[i], f1_scores[i]))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            " [[770  21  40  32  18   6   7  12  64  30]\n",
            " [ 11 859   4   8   7   3   9   7  30  62]\n",
            " [ 60   6 581  66  84  61  66  47  17  12]\n",
            " [ 22  19  57 530  59 145  83  39  21  25]\n",
            " [ 22   4  65  49 690  37  54  53  18   8]\n",
            " [ 15   3  46 179  42 605  41  46  10  13]\n",
            " [  6   6  29  60  32  20 828   7   5   7]\n",
            " [ 23   4  25  45  59  54   7 758   5  20]\n",
            " [ 53  40  14  11   6  11   2   4 831  28]\n",
            " [ 30  95  12  16   0   9   5  13  31 789]]\n",
            "Accuracy of plane : 77 %  Precision: 77.0 %  Recall:   76 %  F1-score: 76.54075546719683 %\n",
            "Accuracy of   car : 85 %  Precision: 85.9 %  Recall:   81 %  F1-score: 83.51968886728245 %\n",
            "Accuracy of  bird : 58 %  Precision: 58.099999999999994 %  Recall:   66 %  F1-score: 62.03950880939668 %\n",
            "Accuracy of   cat : 53 %  Precision: 53.0 %  Recall:   53 %  F1-score: 53.106212424849694 %\n",
            "Accuracy of  deer : 69 %  Precision: 69.0 %  Recall:   69 %  F1-score: 69.10365548322484 %\n",
            "Accuracy of   dog : 60 %  Precision: 60.5 %  Recall:   63 %  F1-score: 62.01947719118401 %\n",
            "Accuracy of  frog : 82 %  Precision: 82.8 %  Recall:   75 %  F1-score: 78.78211227402474 %\n",
            "Accuracy of horse : 75 %  Precision: 75.8 %  Recall:   76 %  F1-score: 76.33434038267875 %\n",
            "Accuracy of  ship : 83 %  Precision: 83.1 %  Recall:   80 %  F1-score: 81.79133858267717 %\n",
            "Accuracy of truck : 78 %  Precision: 78.9 %  Recall:   79 %  F1-score: 79.13741223671015 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775rT7zGqNCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59ba933a-6b1b-4fa4-883b-acfcb46a4f6d"
      },
      "source": [
        "print(precisions)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.758, 0.867, 0.528, 0.55, 0.718, 0.577, 0.836, 0.739, 0.835, 0.768]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8YUR5t71y0c",
        "colab_type": "code",
        "outputId": "135999cf-c05e-4315-9b0d-bcf84386c7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "\n",
        "lr=0.15\n",
        "for epoch in range(4, 10):\n",
        "    lr=lr*0.9\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    optimizer = optim.Adam(model.parameters(), 0.0000001)\n",
        "\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 4 [    0/50000 (0%)]\tLoss: 0.069985\n",
            "Train Epoch: 4 [ 6400/50000 (13%)]\tLoss: 0.080983\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.009544\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.021003\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.006271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0032a4ef17fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-cbee7526d676>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0fgRhoz1xy5",
        "colab_type": "code",
        "outputId": "d2899002-7bf1-4a33-838c-dd99f0b13add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "for epoch in range(10, 30):\n",
        "    lr = lr*15/16\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 10 [    0/50000 (0%)]\tLoss: 0.026206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c6865caf3f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-bf07656fa3cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtbAYwHbfRzh",
        "colab_type": "code",
        "outputId": "97ad19a4-5775-43eb-9bfb-bd4eef182081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "\"\"\"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\"\"\"\n",
        "#000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "#000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "#000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 36, 3, padding=1)\n",
        "        self.bnm1 = nn.BatchNorm2d(36)\n",
        "        self.conv2 = nn.Conv2d(36, 180, 3, padding=1)\n",
        "        self.bnm2 = nn.BatchNorm2d(180)\n",
        "        self.conv3 = nn.Conv2d(180, 720, 3, padding=1)\n",
        "        self.bnm3 = nn.BatchNorm2d(720)\n",
        "        self.conv4 = nn.Conv2d(720, 3600, 3)\n",
        "        self.bnm4 = nn.BatchNorm2d(3600)\n",
        "        self.fc1 = nn.Linear(9*3600, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 620)\n",
        "        self.fc3 = nn.Linear(620, 84)\n",
        "        self.fc4 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.avg_pool2d(x, 2, 2)\n",
        "        x = self.bnm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.avg_pool2d(x, 2, 2)\n",
        "        x = self.bnm3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.avg_pool2d(x, 2, 2)\n",
        "        x = self.bnm4(x)\n",
        "        x = x.view(-1, 9*3600)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "lr=0.25\n",
        "momentum = 0.5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch,log_interval):\n",
        "    model.train()\n",
        "    avg_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # zero the gradient buffers\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() # Does the update\n",
        "        avg_loss+=F.nll_loss(output, target, reduction='sum').item()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{:5.0f}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "    avg_loss/=len(train_loader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss,accuracy\n",
        "\n",
        "epochs = 3\n",
        "log_interval = 50\n",
        "save_model = False\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "accuracy_list = []\n",
        "optimizer = optim.SGD(model.parameters(), lr, momentum=momentum)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "if (save_model):\n",
        "    torch.save(model.state_dict(),\"CIFAR_cnn.pt\")\n",
        "\n",
        "lr=0.15\n",
        "for epoch in range(4, 10):\n",
        "    #lr=lr*2/3\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "for epoch in range(10, 30):\n",
        "    lr = lr*5/6\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    trn_loss = train(model, device, train_loader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, test_loader)\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(36, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(180, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm3): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(720, 3600, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bnm4): BatchNorm2d(3600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=32400, out_features=6000, bias=True)\n",
            "  (fc2): Linear(in_features=6000, out_features=620, bias=True)\n",
            "  (fc3): Linear(in_features=620, out_features=84, bias=True)\n",
            "  (fc4): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Train Epoch: 1 [    0/50000 (0%)]\tLoss: 2.313079\n",
            "Train Epoch: 1 [ 6400/50000 (13%)]\tLoss: 2.073137\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.584232\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.612884\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.527534\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.349164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9f0cb5224967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9f0cb5224967>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}